{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3307b886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/28 18:04:53 WARN Utils: Your hostname, Shumengs-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.1.15 instead (on interface en0)\n",
      "24/02/28 18:04:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/28 18:04:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da8bceb",
   "metadata": {},
   "source": [
    "#### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a4d851a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a55d32",
   "metadata": {},
   "source": [
    "#### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8604058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True),\n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ba58d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema)\\\n",
    "    .csv('fhv_tripdata_2019-10.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12211fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df.repartition(6)\n",
    "df.write.parquet('HW/fhv_2019_10/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23e1e42",
   "metadata": {},
   "source": [
    "#### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d926da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c0dc49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62610"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(col(\"pickup_datetime\").cast(\"date\") == '2019-10-15').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4a3b24",
   "metadata": {},
   "source": [
    "#### Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3196ea13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('fhv_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2cffeeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q4 = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    *,\n",
    "    TIMESTAMPDIFF(SECOND, pickup_datetime, dropoff_datetime) / 3600 as duration_hour\n",
    "FROM\n",
    "    fhv_data\n",
    "ORDER BY TIMESTAMPDIFF(SECOND, pickup_datetime, dropoff_datetime) / 3600 DESC\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f56a885d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 37:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|duration_hour|\n",
      "+-------------+\n",
      "|     631152.5|\n",
      "+-------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_q4.select(['duration_hour']).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b78b69",
   "metadata": {},
   "source": [
    "#### Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc918f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zone = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4cba67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: string (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zone.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0ce9b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df.join(df_zone, df.PULocationID == df_zone.LocationID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ee102ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 60:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+--------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|    Zone|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+--------+\n",
      "|              B02546|2019-10-20 22:07:05|2019-10-20 22:09:27|         264|         235|   null|                B02546|      NV|\n",
      "|              B00310|2019-10-31 11:17:27|2019-10-31 11:24:59|         264|         212|   null|                B00310|      NV|\n",
      "|              B00647|2019-10-31 07:59:07|2019-10-31 08:02:31|         264|          78|   null|                B00647|      NV|\n",
      "|              B01626|2019-10-31 09:40:51|2019-10-31 09:44:14|         264|         130|   null|                B01626|      NV|\n",
      "|     B01711         |2019-10-31 13:13:45|2019-10-31 13:54:57|          92|         173|   null|       B01711         |Flushing|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join = df_join.drop('LocationID','Borough','service_zone')\n",
    "df_join.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b319a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.registerTempTable('hw_q6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cd3b9fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q6 = spark.sql(\"\"\"\n",
    "SELECT \n",
    " \n",
    "    zone,\n",
    "    COUNT(1) AS number_records\n",
    "FROM\n",
    "    hw_q6\n",
    "\n",
    "GROUP BY\n",
    "    1\n",
    "ORDER BY 2 ASC\n",
    "LIMIT 1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "20b92ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 92:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+\n",
      "|       zone|number_records|\n",
      "+-----------+--------------+\n",
      "|Jamaica Bay|             1|\n",
      "+-----------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_q6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5224912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
